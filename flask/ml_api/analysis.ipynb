{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "no such table: image_info",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\admin\\dlgksk\\flask\\ml_api\\analysis.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/dlgksk/flask/ml_api/analysis.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m conn \u001b[39m=\u001b[39m sqlite3\u001b[39m.\u001b[39mconnect(dbname)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/dlgksk/flask/ml_api/analysis.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m cur \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mcursor()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/admin/dlgksk/flask/ml_api/analysis.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m cur\u001b[39m.\u001b[39mexecute(\u001b[39m'\u001b[39m\u001b[39mDROP TABLE image_info\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/dlgksk/flask/ml_api/analysis.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m cur\u001b[39m.\u001b[39mexecute(\u001b[39m'\u001b[39m\u001b[39mCREATE TABLE image_info(id INTEGER PRIMARY KEY AUTOINCREMENT, filename STRING)\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/dlgksk/flask/ml_api/analysis.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m conn\u001b[39m.\u001b[39mcommit()\n",
      "\u001b[1;31mOperationalError\u001b[0m: no such table: image_info"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import sqlite3\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "INCLUDED_EXTENTION = [\".png\", \".jpg\"]\n",
    "\n",
    "dbname = 'images.db'\n",
    "conn = sqlite3.connect(dbname)\n",
    "cur = conn.cursor()\n",
    "cur.execute('DROP TABLE image_info')\n",
    "cur.execute('CREATE TABLE image_info(id INTEGER PRIMARY KEY AUTOINCREMENT, filename STRING)')\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "conn = sqlite3.connect(dbname)\n",
    "cur = conn.cursor()\n",
    "filenames = sorted(os.listdir('handwriting_pics'))\n",
    "for filename in filenames:\n",
    "    base, ext = os.path.splitext(filename)\n",
    "    if ext not in INCLUDED_EXTENTION:\n",
    "        continue\n",
    "    cur.execute('INSERT INTO image_info(filename) values(?)', (filename,))\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "conn = sqlite3.connect(dbname)\n",
    "cur = conn.cursor()\n",
    "cur.execute('SELECT * FROM image_info')\n",
    "pics_info = cur.fetchall()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "img_test = np.empty((0, 64))\n",
    "for pic_info in pics_info:\n",
    "    filename = pic_info[1]\n",
    "    base, ext = os.path.splitext(filename)\n",
    "    if ext not in INCLUDED_EXTENTION:\n",
    "        continue\n",
    "    img = Image.open(f'handwriting_pics/{filename}').convert('L')\n",
    "    img_data256 = 255 - np.array(img.resize((8, 8)))\n",
    "\n",
    "    min_bright = img_data256.min()\n",
    "    max_bright = img_data256.max()\n",
    "    img_data16 = (img_data256 - min_bright) / (max_bright - min_bright) * 16\n",
    "    img_test = np.r_[img_test, img_data16.astype(np.uint8).reshape(1, -1)]\n",
    "\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "logreg = LogisticRegression(max_iter=2000)\n",
    "logreg_model = logreg.fit(X_train, y_train)\n",
    "\n",
    "X_true = []\n",
    "for filename in filenames:\n",
    "    base, ext = os.path.splitext(filename)\n",
    "    if ext not in INCLUDED_EXTENTION:\n",
    "        continue\n",
    "    X_true = X_true + [int(filename[:1])]\n",
    "X_true = np.array(X_true)\n",
    "pred_logreg = logreg_model.predict(img_test)\n",
    "\n",
    "print('손글씨 문자의 판별 결과')\n",
    "print('관측 결과:', X_true)\n",
    "print('예측 결과:', pred_logreg)\n",
    "print('정답률:', logreg_model.score(img_test, X_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INCLUDED_EXTENTION = [\".png\", \".jpg\"]\n",
    "\n",
    "# 이미지가 들어있는 폴더를 지정하고, 내용의 파일명을 취득\n",
    "# images.db를 신규 작성. images.db가 이미 존재하고 있으면 접속.\n",
    "dbname = 'images.db'\n",
    "# 데이터베이스로의 커넥션 오브젝트 작성\n",
    "conn = sqlite3.connect(dbname)\n",
    "# sqlite를 조작하는 커서 오브젝트를 작성\n",
    "cur = conn.cursor()\n",
    "# 데이터베이스의 초기화\n",
    "cur.execute('DROP TABLE image_info')\n",
    "# image_info라는 table을 작성\n",
    "cur.execute('CREATE TABLE image_info (id INTEGER PRIMARY KEY AUTOINCREMENT, filename STRING)')\n",
    "# 데이터베이스에 커밋하고, 변경을 보존\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "# 데이터베이스에 이미지의 파일명을 삽입\n",
    "conn = sqlite3.connect(dbname)\n",
    "cur = conn.cursor()\n",
    "filenames = sorted(os.listdir('handwriting_pics'))\n",
    "for filename in filenames:\n",
    "    base, ext = os.path.splitext(filename)\n",
    "    if ext not in INCLUDED_EXTENTION:\n",
    "        continue\n",
    "    cur.execute('INSERT INTO image_info(filename) values(?)', (filename,))\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "# table의 내용을 취득\n",
    "conn = sqlite3.connect(dbname)\n",
    "cur = conn.cursor()\n",
    "cur.execute('SELECT * FROM image_info')\n",
    "# fetchall()을 사용해서 내용을 전부 취득\n",
    "pics_info = cur.fetchall()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test = np.empty((0, 64))\n",
    "#　폴더 내의 전 이미지를 데이터화\n",
    "for pic_info in pics_info:\n",
    "    filename = pic_info[1]\n",
    "    #　이미지 파일을 취득, 그레이스케일로 하여 크기 변경\n",
    "    base, ext = os.path.splitext(filename)\n",
    "    if ext not in INCLUDED_EXTENTION:\n",
    "        continue\n",
    "    img = Image.open(f'handwriting_pics/{filename}').convert('L')\n",
    "    img_data256 = 255 - np.array(img.resize((8, 8)))\n",
    "\n",
    "    # 이미지 데이터 내의 최솟값이 0, 최댓값이 16이 되도록 계산\n",
    "    min_bright = img_data256.min()\n",
    "    max_bright = img_data256.max()\n",
    "    img_data16 = (img_data256 - min_bright) / (max_bright - min_bright) * 16\n",
    "    # 가공한 이미지 데이터의 배열을 합친다\n",
    "    img_test = np.r_[img_test, img_data16.astype(np.uint8).reshape(1, -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지도 데이터로부터의 학습\n",
    "# sklearn의 데이터셋으로부터 취득, 목적 변수 X와 설명 변수 y로 나눈다\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "# 지도 데이터와 테스트 데이터로 나눈다\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "# 로지스틱 회귀의 모델을 작성하고, 지도 데이터를 사용해서 학습시킨다\n",
    "logreg = LogisticRegression(max_iter=2000)\n",
    "logreg_model = logreg.fit(X_train, y_train)\n",
    "\n",
    "# 이미지 데이터의 판별\n",
    "# 이미지 데이터의 정답을 배열로 한다\n",
    "X_true = []\n",
    "for filename in filenames:\n",
    "    base, ext = os.path.splitext(filename)\n",
    "    if ext not in INCLUDED_EXTENTION:\n",
    "        continue\n",
    "    X_true = X_true + [int(filename[:1])]\n",
    "X_true = np.array(X_true)\n",
    "\n",
    "# 로지스틱 회귀의 학습 완료 모델에 이미지 데이터를 넣고, 판별한다\n",
    "pred_logreg = logreg_model.predict(img_test)\n",
    "\n",
    "print('손글씨 문자의 판별 결과')\n",
    "print('관측 결과:', X_true)\n",
    "print('예측 결과:', pred_logreg)\n",
    "print('정답률:', logreg_model.score(img_test, X_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import sqlite3\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INCLUDED_EXTENTION = [\".png\", \".jpg\"]\n",
    "dbname = 'images.db'\n",
    "dir_name = 'handwriting_pics'\n",
    "\n",
    "def load_filenames(dir_name, included_ext=INCLUDED_EXTENTION):\n",
    "    \"\"\"손글씨 문자 이미지가 놓여 있는 패스로부터 파일명을 취득하고, 리스트를 작성\"\"\"\n",
    "    files = []\n",
    "    filenames = sorted(os.listdir(dir_name))\n",
    "    for filename in filenames:\n",
    "        base, ext = os.path.splitext(filename)\n",
    "        if ext not in included_ext:\n",
    "            continue\n",
    "        files.append(filename)\n",
    "    return files\n",
    "\n",
    "def create_table(dbname):\n",
    "    \"\"\"테이블을 작성하는 함수\"\"\"\n",
    "    conn = sqlite3.connect(dbname)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('DROP TABLE image_info')\n",
    "    cur.execute( 'CREATE TABLE image_info (id INTEGER PRIMARY KEY AUTOINCREMENT, filename STRING)')\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(\"table is successully created\")\n",
    "\n",
    "def insert_filenames(dbname, dir_name):\n",
    "    \"\"\"손글씨 문자 이미지의 파일명을 데이터베이스에 보존\"\"\"\n",
    "    filenames = load_filenames(dir_name)\n",
    "    conn = sqlite3.connect(dbname)\n",
    "    cur = conn.cursor()\n",
    "    for filename in filenames:\n",
    "        cur.execute('INSERT INTO image_info(filename) values(?)', (filename,))\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    print(\"image file names are successully inserted\")\n",
    "\n",
    "def extract_filenames(dbname):\n",
    "    \"\"\"손글씨 문자 이미지의 파일명을 데이터베이스로부터 취득\"\"\"\n",
    "    conn = sqlite3.connect(dbname)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute( 'SELECT * FROM image_info')\n",
    "    filenames = cur.fetchall()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return filenames\n",
    "\n",
    "create_table(dbname)\n",
    "insert_filenames(dbname, dir_name)\n",
    "extract_filenames(dbname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p425, 아웃풋을 확인 필요\n",
    "def load_filenames(dir_name, included_ext=INCLUDED_EXTENTION):\n",
    "    \"\"\"손글씨 문자 이미지가 놓여 있는 패스로부터 파일명을 취득하고, 리스트를 작성하는 함수\"\"\"\n",
    "    files = []\n",
    "    filenames = sorted(os.listdir(dir_name))\n",
    "    for filename in filenames:\n",
    "        base, ext = os.path.splitext(filename)\n",
    "        if ext not in included_ext:\n",
    "            continue\n",
    "        files.append(filename)\n",
    "    return files\n",
    "\n",
    "def get_grayscale(dir_name):\n",
    "    \"\"\"읽어 들인 손글씨 문자 이미지의 색을 그레이스케일로 변환하는 함수(그레이스케일은 색의 농담의 명함을 나누는 방법)\"\"\"\n",
    "    filenames = load_filenames(dir_name)\n",
    "    for filename in filenames:\n",
    "        img = Image.open(f'{dir_name}/{filename}').convert('L')\n",
    "        yield img\n",
    "\n",
    "def get_shrinked_img(dir_name):\n",
    "    \"\"\"이미지 크기를 8×8 픽셀의 크기로 통일하고, 밝기도 16계조의 그레이스케일로 흑백으로 변환하는 함수\"\"\"\n",
    "    img_test = np.empty((0, 64))\n",
    "    crop_size = 8\n",
    "    for img in get_grayscale(dir_name):\n",
    "        img_data256 = 255 - np.array(img.resize((crop_size, crop_size)))\n",
    "        min_bright, max_bright = img_data256.min(),  img_data256.max()\n",
    "        img_data16 = (img_data256 - min_bright) / (max_bright - min_bright) * 16\n",
    "        img_test = np.r_[img_test, img_data16.astype(np.uint8).reshape(1, -1)]\n",
    "    return img_test\n",
    "\n",
    "img_test = get_shrinked_img(dir_name)\n",
    "get_shrinked_img(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_filenames(dir_name, included_ext=INCLUDED_EXTENTION):\n",
    "    \"\"\"손글씨 문자 이미지가 놓여 있는 파일명을 취득하고, 리스트를 작성\"\"\"\n",
    "    files = []\n",
    "    filenames = sorted(os.listdir(dir_name))\n",
    "    for filename in filenames:\n",
    "        base, ext = os.path.splitext(filename)\n",
    "        if ext not in included_ext:\n",
    "            continue\n",
    "        files.append(filename)\n",
    "    return files\n",
    "\n",
    "def create_logreg_model():\n",
    "    \"\"\"로지스틱 회귀의 학습 완료 모델을 생성\"\"\"\n",
    "    digits = load_digits()\n",
    "    X = digits.data\n",
    "    y = digits.target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "    logreg = LogisticRegression(max_iter=2000)\n",
    "    logreg_model = logreg.fit(X_train, y_train)\n",
    "    return logreg_model\n",
    "\n",
    "def evaluate_probs(dir_name, img_test, logreg_model):\n",
    "    \"\"\"테스트 데이터를 이용하여 로지스틱 회귀의 학습 완료 모델의 아웃풋을 평가\"\"\"\n",
    "    filenames = load_filenames(dir_name)\n",
    "    X_true = [int(filename[:1]) for filename in filenames]  \n",
    "    X_true = np.array(X_true)\n",
    "    pred_logreg = logreg_model.predict(img_test)\n",
    "    \n",
    "    print('손글씨 문자의 판별 결과')\n",
    "    print('관측 결과:', X_true)\n",
    "    print('예측 결과:', pred_logreg)\n",
    "    print('정답률:', logreg_model.score(img_test, X_true))\n",
    "    return \"Propability calculation is successfully finished\"\n",
    "\n",
    "logreg_model = create_logreg_model()\n",
    "evaluate_probs(dir_name, img_test, logreg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "logreg = LogisticRegression(max_iter=2000)\n",
    "model = logreg.fit(X_train, y_train)\n",
    "with open('model.pickle', mode='wb') as fp:\n",
    "    pickle.dump(model, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
